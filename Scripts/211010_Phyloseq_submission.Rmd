---
title: "Phyloseq"
author: "Your Name"
date: "11/10/2021"
output: github_document
---

# Intro

We explore the processed ACIDD 16S sequences using [phyloseq](https://joey711.github.io/phyloseq/)

# Install phyloseq

```{r}
#BiocManager::install("phyloseq")
```


```{r message = F, warning = F}
library(tidyverse) 
library(phyloseq)
library(RColorBrewer)
library(readxl)
library(lubridate)
```

# Import Data 

```{r message = F}
count.tab <- read_rds("~/Documents/144l_students_2021/Input_Data/week7/seqtab-nochimtaxa.rds") #table of counts for each sequence in each sample
tax.tab <- read_rds("~/Documents/144l_students_2021/Input_Data/week7/taxa.rds") #table that matches ASV to sequence

#you will need to download the ACIDD_Exp_Processed_DOC_BGE.rds and the ACIDD_Exp_BactAbund.xlsx files from Justine's Github repository (located in Input_Data/week7/) and put them into your own local Input Data folder
metadata_OG <- read_excel("~/Documents/144l_students_2021/Input_Data/week7/ACIDD_Exp_BactAbund.xlsx", sheet = "Metadata")
glimpse(metadata_OG)
metadata <- metadata_OG %>%
  mutate(Datetime = ymd_hm(Datetime))
glimpse(metadata)
metadata_doc <- read_rds("~/Documents/144l_students_2021/Input_Data/week7/ACIDD_Exp_Processed_DOC_BGE.rds")
glimpse(metadata_doc)
join <- left_join(metadata_doc, metadata)
sample.tab <- join %>%
  drop_na(DNA_SampleID) %>% 
  column_to_rownames(var = "DNA_SampleID") 
```

# Phyloseq Object

We need to create a phyloseq object that merges all three datasets. Sometimes this doesn't work beacuse of the format of the data files. Make sure all the sample names between the sampleinfo.txt and seqtab-nochimtaxa.txt are the same

```{r}
OTU = otu_table(count.tab, taxa_are_rows = TRUE) 
TAX = tax_table(tax.tab)
SAM = sample_data(sample.tab)
ps = phyloseq(OTU,TAX,SAM) 
```

# Filter sequences

We will filter out chloroplasts and mitochondria, because we only intended to amplify bacterial sequences. It's good to check you don’t have anything lurking in the taxonomy table. 

```{r}
sub_ps <- ps %>%
  # subset_samples(Experiment == "ASH172") %>%  #use this function if you want to only include some subset of your sample set in the subsequent analysis
  subset_taxa(Family  != "mitochondria" & Order  != "Chloroplast")
```

Q1: What did we do in the code chunk above? (What is the difference between phyloseq object ps and phyloseq object sub_ps?) Why did we do this? 

A1: 

# Sample Summary

As a first analysis, we will look at the distribution of read counts from our samples

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 6, fig.align = "center"}
# Make a data frame with a column for the read counts of each sample
sample_sum_df <- data.frame(sum = sample_sums(sub_ps))
# Histogram of sample read counts
ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "#377EB8", binwidth = 1000) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  theme(axis.title.y = element_blank()) +
  theme_bw()
```
Q2: Describe what "sequencing depth" means in your own words. 

A2: 

```{r}
# mean, max and min of sample read counts
summary(sample_sum_df)
```


# Beta Diversity

Beta diversity involves calculating metrics such as distances or dissimilarities based on pairwise comparisons of samples – they don’t exist for a single sample, but rather only as metrics that relate samples to each other. i.e. beta diversity = patterns in community structure between samples

Since differences in sampling depths between samples can influence distance/dissimilarity metrics, we first need to somehow normalize the read depth across our samples.

## Subsample

We will rarefy (random subsample with replacement) the read depth of the samples first (scale to the smallest library size).

[Case for not subsampling]( https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531)

[Response blog for subsampling](https://www.polarmicrobes.org/how-i-learned-to-stop-worrying-and-love-subsampling-rarifying/)

Read depth is an artefact of a machine made by a company in San Diego, not anything about your samples or their biology. It is totally artifactual, and controlling for artifacts is critical in science. Subsampling randomly is the simplest way to control for this, and the question is whether this is the "best" way of controlling for it. See links above for alternative arguments about what the best way of controlling for this artefact is. 

A strong reason to subsample is to standardize effort. The bottom line is that in all experimental design you should not be comparing things to which you devote different effort in resolution. For instance, you don't sample one site once a week and another once a month if you want to compare the dynamics between the sites. You standardize effort.

With that said, the bigger your differential in mean (or median) read depth (reads/sample) between pre- and post-subsampling, the greater the "effect" on beta diversity. 

Examples:

- means reads before = 40k, mean reads after = 1k, big effect.
- mean reads before = 40k, mean reads after = 20k, small effect.
- mean reads before = 2k, mean reads after = 1k, small effect.


We will subsample to the minimum read depth of all samples and not subsample. We'll then compare the mean reads pre- and post-subsampling and also compare beta diversity patterns

```{r}
ps_min <-  rarefy_even_depth(sub_ps, sample.size = min(sample_sums(sub_ps)))

mean(sample_sums(sub_ps)) #7686
mean(sample_sums(ps_min)) #6048 this is also the same as min(sample_sums(sub)ps) 
```

Q3: Do you think that the subsampling we did here will have a large effect on our beta diveristy analyses? why or why not? 

A3: 

## NMDS

One of the best exploratory analyses for amplicon data is unconstrained ordinations. Here we will look at non-metric multidimensional scaling (NMDS) ordinations of our full community samples. For NMDS plots it’s important to set a seed since the starting positions of samples in the algorithm is random.

```{r}
set.seed(1)
# Ordinate
nmds <- ordinate(sub_ps, method = "NMDS",  distance = "bray") # stress = 0.04
```

```{r}
set.seed(1)
# Ordinate
nmds_min <- ordinate(ps_min, method = "NMDS",  distance = "bray") # stress = 0.04
```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 6, fig.align = "center"}
levels <- c("Control", "Ash Leachate", "San Diego", "Santa Barbara")

nmds.plot <- plot_ordination(sub_ps, nmds,  title = "NMDS") +
   geom_point(aes(fill = days, shape = factor(Treatment, levels = levels)), alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_gradient(low = "#0db5e6", high = "#d31f2a") +
  theme_bw() 

#removing one of the plotting layers (there are points within points)
nmds.plot$layers <- nmds.plot$layers[-1]

nmds.plot + 
  facet_grid(~Location) +
  guides(fill = guide_colorbar(title = "Days"), shape = guide_legend(title = "Treatment"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 6, fig.align = "center"}
nmds_min.plot <- plot_ordination(ps_min, nmds_min,  title = "NMDS") +
   geom_point(aes(fill = days, shape = factor(Treatment, levels = levels)), alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_gradient(low = "#0db5e6", high = "#d31f2a") +
  theme_bw() 

#removing one of the plotting layers (there are points within points)

nmds_min.plot$layers <- nmds_min.plot$layers[-1]

nmds_min.plot + 
  facet_grid(~Location) +
  guides(fill = guide_colorbar(title = "Days"), shape = guide_legend(title = "Treatment"))
```

NMDS plots attempt to show ordinal distances between samples as accurately as possible in two dimensions. It is important to report the stress of these plots, because a high stress value means that the algorithm had a hard time representing the distances between samples in 2 dimensions. The stress of this plot was good - it was .04 (generally anything below .2 is considered acceptable). 

Q4: Which datasets were used to make the two NMDS plots above? Based on how these two plots look, which dataset are we going to move forward with and why? 

A4: 

Q5: Describe in a couple of sentences what patterns you see in the beta diversity of the communities in the control and Ash Leachate treatments. 

A5: 

# Alpha Diversity


Estimating alpha diversity of microbial communities is [problematic](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC93182/) no matter what you do. 

We are going to calculate the Chao1 index for richness and the Shannon diversity index. 

**it is important to note that the alpha diversity values are not interpretable as “real” numbers of anything (due to the nature of amplicon data), but they can still be useful as relative metrics of comparison. If Chao1 richness goes up, but Shannon diversity goes down, it indicates that the sample may have more ASVs but is dominated by a few of them.**

We will use the subsampled library, which retains estimates of the species abundance of the real population while standardizing sampling effort.

[subsampling  and alpha diversity paper](https://www.frontiersin.org/articles/10.3389/fmicb.2019.02407/full)

[Chao1: nonparametric estimation of minimum community richness](https://www.jstor.org/stable/4615964?seq=1#metadata_info_tab_contents) 


```{r}
richness <- estimate_richness(ps_min, measures = c("Chao1", "Shannon")) %>% 
  rownames_to_column(., var = "DNA_ID") %>% 
  mutate_at(vars(DNA_ID), str_replace_all, pattern = "171.", "171-") %>% 
   mutate_at(vars(DNA_ID), str_replace_all, pattern = "172.", "172-")
```


Let’s add the sample metadata into this dataframe 

```{r}
alphadiv <- left_join(richness, sample.tab %>% rownames_to_column(., var = "DNA_ID")) 
```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 8, fig.align = "center"}

# install.packages("ggpubr")
library(ggpubr)

pivot.data <- alphadiv %>% 
  select(Treatment, Location, Bottle, Timepoint, days, Chao1, Shannon) %>% 
  pivot_longer(.,  cols = c(Chao1,  Shannon), names_to = "measure", values_to = "est" ) %>% 
  left_join(., alphadiv %>% 
              select(Treatment, Location, Bottle, Timepoint, days, se.chao1)) %>% 
  mutate(se.chao1 = ifelse(measure == "Chao1", se.chao1, NA)) 

alpha.plot <- ggboxplot(pivot.data, x = "Timepoint", y = "est",
            # color = "Location",
            # palette = c("#0db5e6","#d31f2a"),
            xlab = expression(italic(paste(""))), 
            ylab = expression(italic(paste("Alpha Diversity Measure"))),
            add = "dotplot",
            width = 0.2,
            ggtheme = theme_bw()) +  
  stat_compare_means(label.x = "6") +
  facet_grid(measure~ factor(Treatment, levels = levels), scales = "free") 

alpha.plot
```

Boxes represent the 1.5 interquartile range, with the internal solid line representing the median. Circles represent data points. p-values are reported  the non-parametric two sample Wilcoxon test, which tests whether the means between two groups are equal (ns: p > 0.05, * : p≤ 0.05, ** : p ≤ 0.01).

Difference in the alpha diversity indexes among conditions were tested using pairwise Wilcoxon tests; p < 0.05 was considered the threshold significance for a difference between conditions.

From this plot we can see within the treatments that the richness (via Chao index) of our samples significantly changed, while overall diversity (via Shannon index) did not change. This suggest that while richness decreased in both the control and ash leachate treatments, the eveness was similar between the initial and final conditions. 

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 8, fig.align = "center"}

alpha.plot2 <-  ggboxplot(pivot.data, x = "Treatment", y = "est", 
            # color = "Location",
            # palette = c("#0db5e6","#d31f2a"),
            xlab = expression(italic(paste(""))), 
            ylab = expression(italic(paste("Alpha Diversity Measure"))),
            add = "dotplot",
            width = 0.2,
            ggtheme = theme_bw()) +  
  stat_compare_means(label.x = "Ash Leachate") +
  facet_grid(measure~Timepoint, scales = "free") 

alpha.plot2
```

From this plot we can see between the treatments that the richness of the control samples were higher at the initial condition than the ash leachate, suggesting that there may have been some quality control issues as we would expect the initial samples to all have the same richness. By timepoint 6, it looks like the richness was about the same between the control and the ash leachate. Overall diversity was similar between the treatments at the initial condition, but not by the end of the experiment. The ash leachate samples at timepoint 6 may have been less even.  

Q6: Summarize the major takeaways from the alpha diversity plots you generated. 

A6: 

# Who??

Which taxa were important? Which taxa were contributing to the change in community compositon?

**Note: Recovered 16S rRNA gene copy numbers do not equal organism abundance.**

That said, we can generate a heat map of our samples showing us how the relative abundance of different taxonomic groups change...potentially giving us a visual of which taxa are most important to the alpha and beta diversity patterns we observed. 
First, we're going to generate a custom table that will be easier to work with than a phyloseq object.

## Generate relative abundances

Our data currently shows number gene copies recovered, so we'll convert to percentages (relative abundances)

```{r}
ps_std <- transform_sample_counts(ps_min, function(x) x/sum(x))
#extract the relative abundance table and coerce into dataframe
ps_std.tab <- as(otu_table(ps_std), "matrix")
ps_std.df = as.data.frame(ps_std.tab) 
```

## Make table

```{r warning = F}
#first coerce the taxa table into a data frame
tax.df <-  as.data.frame(tax.tab) 
#then combine the data frames
custom.tab <- tax.df %>% 
  rownames_to_column(., var = "asv") %>% 
  left_join(., ps_std.df %>% rownames_to_column(., var = "asv")) %>% 
  #create a new index of that combines the  class, order, family, and genus values, you can play around here!!
  mutate(#pcofg = paste(Phylum, "_", Class, "_", Order,"_", Family, "_", Genus),
         # pcof = paste(Phylum, "_", Class, "_", Order,"_", Family,),
         pco = paste(Phylum, "_", Class, "_", Order)) %>% 
  select(-c(asv:Genus)) %>% 
  # select(pcof,everything()) %>% 
  # group_by(pcof) %>% 
  select(pco,everything()) %>% 
  group_by(pco) %>% 
  #here we are combining the relative abundances based on our grouping
  summarise_at(vars(contains(c("ASH171", "ASH172"))), sum, na.rm = T) %>% 
  ungroup()

#save the row names and then make them into the column names
colnames <- custom.tab[,1] 

#transpose the dataframe so we can merge with the sample info table
t_custom.tab <-  as.data.frame(t(custom.tab[,-1]))
# colnames(t_custom.tab) <- colnames$pcof
colnames(t_custom.tab) <- colnames$pco

#merge
sweet.tab <- t_custom.tab %>% 
  rownames_to_column(., var = "sample") %>% 
  left_join(., sample.tab %>% rownames_to_column(., var = "sample") %>% select(sample, Experiment, Location, Bottle, Treatment, Timepoint, days, cells)) %>% 
  select(sample, Experiment:cells, everything())


relabund <- sweet.tab %>% 
  select(-c(sample:cells)) %>% 
  #remove groups that are completely absent
  .[ , colSums(.) > 0] %>% 
  #arrange by biggest contributors
  .[, order(colSums(-.))] %>% 
  bind_cols(sweet.tab %>% select(sample:cells), .)
```

## Heatmap

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 16, fig.width = 10, fig.align = "center"}
relaheat.data <- relabund %>% 
  select(-c(sample, Experiment, Location, Bottle, days, cells)) %>%
  pivot_longer(.,-c(Treatment:Timepoint), names_to = "taxa", values_to = "relabund") %>% 
  separate(taxa, into = c("p", "c", "o"), sep = " _ ") %>% 
  group_by(Treatment, Timepoint, p, c, o) %>% 
  mutate(mean_relabund = mean(relabund, na.rm = T)) %>% 
  ungroup() %>% 
  select(-relabund) %>% 
  distinct()

# install.packages("viridis")
library(viridis)

relaheat <- relaheat.data %>%
  ggplot(aes(x = Timepoint, y = o)) +
  geom_tile(aes(fill = mean_relabund), color = "white") +
  scale_fill_viridis(option = "D") +
  labs(x = "Timepoint", y = "Order", fill = "Relative Abundance") +
facet_grid(~factor(Treatment, levels = levels)) +
  theme_bw() +
  theme(axis.text.y = element_text(size = 12),
        legend.position = "top") +
   guides(fill = guide_colourbar(barheight = 2, barwidth = 20, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), color = F) 

relaheat
```

Q7: Who uniquely increased in relative abundance in the ash leachate treatment that did not in the control? what about decrease?

A7: 

Everything shown here is just a snapshot of what you can look at with your community composition data. There are many other resources you can use to get ideas of how to look at different aspects of your data, including the [phyloseq tutorial](https://joey711.github.io/phyloseq/) and [happy belly bioinformatics](https://astrobiomike.github.io). It's up to you and your questions!!

# Save and knit

```{r}
saveRDS(sweet.tab, "~/Documents/144l_students_2021/Output_Data/week7/Custom_ASV_Table.rds")
saveRDS(sub_ps, "~/Documents/144l_students_2021/Output_Data/week7/phyloseq_obj.rds")
saveRDS(ps_min, "~/Documents/144l_students_2021/Output_Data/week7/subsampled_phyloseq_obj.rds")
saveRDS(alphadiv, "~/Documents/144l_students_2021/Output_Data/week7/alphadiv.rds")

```


# Stacked Barplots

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 8, fig.align = "center"}

relabar.data <- relabund %>% 
  select(-c(sample, Experiment, days, cells)) %>%
  pivot_longer(.,-c(Location:Timepoint), names_to = "taxa", values_to = "relabund") %>% 
  group_by(Treatment, Timepoint, taxa) %>% 
  mutate(mean_relabund = mean(relabund, na.rm = T)) %>% 
  ungroup() %>% 
  separate(taxa, into = c("p", "c", "o"), sep = " _ ") %>% 
  select(Treatment, Timepoint, p, c, o, mean_relabund) %>% 
  distinct() 

# Plot 

relabar.data %>% 
  mutate(Timepoint = as.character(Timepoint)) %>% 
  ggplot(., aes(x =  Timepoint, y = mean_relabund)) + 
  geom_bar(aes(fill = o), color = "black", stat = "identity", position = "stack", width = 0.25, stroke = 1) +
 # scale_fill_manual(values = cal_palette("figmtn", n = 19, type = "continuous")) +
  labs(x = "Timepoint", y = "Relative Abundance") +
  theme_bw() +
  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, kerheight = 1, title = "Order")) +
  facet_grid(~factor(Treatment, levels = levels))
```